* Event Queue
:PROPERTIES:
:TOC: :include descendants
:END:

:CONTENTS:
- [[#concepts-and-purpose][Concepts and purpose]]
  - [[#event-buffering-and-decoupling][Event buffering and decoupling]]
  - [[#thread-safe-operations][Thread-safe operations]]
  - [[#queue-capacity-management][Queue capacity management]]
  - [[#observability-integration][Observability integration]]
- [[#design-and-implementation][Design and implementation]]
  - [[#queue-structure][Queue structure]]
  - [[#queue-initialization][Queue initialization]]
  - [[#event-enqueuing][Event enqueuing]]
  - [[#event-dequeuing][Event dequeuing]]
  - [[#queue-size-monitoring][Queue size monitoring]]
- [[#usage-examples][Usage examples]]
  - [[#creating-an-event-queue][Creating an event queue]]
  - [[#enqueuing-and-dequeuing-events][Enqueuing and dequeuing events]]
  - [[#handling-queue-capacity][Handling queue capacity]]
  - [[#integrating-with-metrics][Integrating with metrics]]
:END:

** Concepts and purpose

*** Event buffering and decoupling

- Event buffering :: The event queue provides a buffer between event producers and consumers that:
  - Decouples components :: Separates event producers (API) from consumers (workers)
  - Handles load spikes :: Absorbs temporary spikes in event creation
  - Enables asynchronous processing :: Allows producers to continue without waiting for processing
  - Provides FIFO ordering :: Ensures events are processed in the order they were received
  This buffering enables a more resilient and responsive architecture.

*** Thread-safe operations

- Concurrency safety :: The event queue provides thread-safe operations for:
  - Concurrent producers :: Multiple API handlers can safely add events simultaneously
  - Concurrent consumers :: Multiple workers can safely retrieve events simultaneously
  - Safe size reporting :: Queue size can be safely checked without disrupting operations
  This thread safety ensures reliable operation in a concurrent environment.

*** Queue capacity management

- Capacity control :: The event queue implements capacity management to:
  - Prevent memory exhaustion :: Limits the maximum number of events in the queue
  - Apply backpressure :: Rejects new events when the queue is full
  - Provide clear feedback :: Returns appropriate errors when capacity is reached
  This capacity management ensures system stability under high load.

*** Observability integration

- Monitoring :: The event queue integrates with observability tools to provide:
  - OpenTelemetry tracing :: Tracks queue operations with distributed tracing
  - Queue size monitoring :: Enables real-time monitoring of queue utilization
  - Queue wait time :: Measures how long events spend in the queue
  These monitoring capabilities enable effective system oversight.

** Design and implementation

*** Queue structure

- EventQueue struct :: Defines the structure and properties of the event queue
  - Channel-based queue :: Uses a Go channel for efficient event buffering
  - Configurable capacity :: Sets queue size based on configuration
  - Thread-safety :: Includes mutex for concurrent operations
  #+BEGIN_SRC go
type EventQueue struct {
	Capacity int64
	mu       sync.RWMutex
	Events   chan Event
}
  #+END_SRC

*** Queue initialization

- NewEventQueue function :: Creates and initializes a new event queue
  - Configurable size :: Uses size defined in command line configuration
  - Channel creation :: Creates a buffered channel for event storage
  - Default capacity :: Sets initial capacity from configuration
  #+BEGIN_SRC go
func NewEventQueue() *EventQueue {
	eq := make(chan Event, CmdEventQueueSize)
	return &EventQueue{
		Capacity: int64(CmdEventQueueSize),
		Events:   eq,
	}
}
  #+END_SRC

*** Event enqueuing

- PutEvent method :: Adds an event to the queue
  - Tracing integration :: Creates a span for tracking the operation
  - Capacity checking :: Verifies there's room in the queue before adding
  - Timestamp recording :: Sets the enqueue time for wait time tracking
  - Automatic typing :: Handles different event types appropriately
  #+BEGIN_SRC go
func (eq *EventQueue) PutEvent(ctx context.Context, event Event) error {
	_, span := otel.Tracer("EventQueue.PutEvent.Tracer").Start(ctx, "EventQueue.PutEvent.Span")
	defer span.End()

	if len(eq.Events) == cap(eq.Events) {
		return errors.New("event queue is full")
	}

	// Set the enqueue time if the event implements BaseEvent
	if baseEvent, ok := event.(*EventLog); ok {
		baseEvent.BaseEvent.EnqueueTime = time.Now()
	} else if baseEvent, ok := event.(*EventMetric); ok {
		baseEvent.BaseEvent.EnqueueTime = time.Now()
	}

	// Append to the Queue
	eq.Events <- event
	return nil
}
  #+END_SRC

*** Event dequeuing

- GetEvent method :: Removes and returns an event from the queue
  - Empty queue handling :: Returns nil when queue is empty
  - Tracing integration :: Creates a span for tracking the operation
  - Channel management :: Uses channel operation to get the next event
  #+BEGIN_SRC go
func (eq *EventQueue) GetEvent(ctx context.Context) Event {
	// Check if the queue is empty
	if len(eq.Events) == 0 {
		return nil
	}
	_, span := otel.Tracer("EventQueue.GetEvent.Tracer").Start(ctx, "EventQueue.GetEvent.Span")
	defer span.End()
	span.AddEvent("Event removed from queue")
	return <-eq.Events
}
  #+END_SRC

*** Queue size monitoring

- Size method :: Returns the current number of events in the queue
  - Tracing integration :: Creates a span for tracking the operation
  - Current size :: Returns the current length of the events channel
  #+BEGIN_SRC go
func (eq *EventQueue) Size(ctx context.Context) int {
	_, span := otel.Tracer("EventQueue.Size.Tracer").Start(ctx, "EventQueue.Size.Span")
	defer span.End()
	return len(eq.Events)
}
  #+END_SRC

** Usage examples

*** Creating an event queue

Example of creating an event queue:

#+BEGIN_SRC go
// Set queue size through command line flag or environment variable
models.CmdEventQueueSize = 100

// Create a new event queue
eventQueue := models.NewEventQueue()

// Print queue capacity
fmt.Printf("Event queue created with capacity: %d\n", eventQueue.Capacity)
#+END_SRC

*** Enqueuing and dequeuing events

Example of adding and retrieving events:

#+BEGIN_SRC go
// Create an event
logEvent := models.NewEventLog(
    uuid.New().String(),
    "info",
    "System started",
)

// Add to queue
ctx := context.Background()
err := eventQueue.PutEvent(ctx, logEvent)
if err != nil {
    fmt.Printf("Failed to queue event: %v\n", err)
    return
}

// Process events from the queue
for {
    event := eventQueue.GetEvent(ctx)
    if event == nil {
        // Queue is empty
        break
    }
    
    // Process the event based on type
    switch e := event.(type) {
    case *models.EventLog:
        fmt.Printf("Log event: [%s] %s\n", e.Level, e.Message)
    case *models.EventMetric:
        fmt.Printf("Metric event: %.2f\n", e.Value)
    }
}
#+END_SRC

*** Handling queue capacity

Example of handling a full queue:

#+BEGIN_SRC go
// Function to add events with full queue handling
func addEventWithRetry(ctx context.Context, queue *models.EventQueue, event models.Event, maxRetries int) error {
    // Try to add the event with retries
    for i := 0; i < maxRetries; i++ {
        err := queue.PutEvent(ctx, event)
        if err == nil {
            return nil
        }
        
        if strings.Contains(err.Error(), "queue is full") {
            // Queue is full, wait and retry
            fmt.Printf("Queue full, retrying in %d ms...\n", (i+1)*100)
            time.Sleep(time.Duration(i+1) * 100 * time.Millisecond)
            continue
        }
        
        // Some other error
        return err
    }
    
    return fmt.Errorf("failed to add event after %d retries: queue is full", maxRetries)
}
#+END_SRC

*** Integrating with metrics

Example of monitoring queue usage with Prometheus:

#+BEGIN_SRC go
// Create queue size metric
queueSize := prometheus.NewGaugeFunc(
    prometheus.GaugeOpts{
        Namespace: "application",
        Subsystem: "queue",
        Name:      "current_size",
        Help:      "Current number of events in the queue",
    },
    func() float64 {
        return float64(eventQueue.Size(context.Background()))
    },
)

// Create queue capacity metric
queueCapacity := prometheus.NewGauge(
    prometheus.GaugeOpts{
        Namespace: "application",
        Subsystem: "queue",
        Name:      "capacity",
        Help:      "Total capacity of the event queue",
    },
)
queueCapacity.Set(float64(eventQueue.Capacity))

// Register metrics
prometheus.MustRegister(queueSize, queueCapacity)
#+END_SRC