* Event Worker
:PROPERTIES:
:TOC: :include descendants
:END:

:CONTENTS:
- [[#concepts-and-purpose][Concepts and purpose]]
  - [[#asynchronous-event-processing][Asynchronous event processing]]
  - [[#worker-lifecycle-management][Worker lifecycle management]]
  - [[#event-processing-reliability][Event processing reliability]]
  - [[#observability-integration][Observability integration]]
- [[#design-and-implementation][Design and implementation]]
  - [[#worker-structure][Worker structure]]
  - [[#worker-initialization][Worker initialization]]
  - [[#event-processing-loop][Event processing loop]]
  - [[#event-processing-implementation][Event processing implementation]]
  - [[#graceful-shutdown][Graceful shutdown]]
- [[#usage-examples][Usage examples]]
  - [[#creating-and-running-a-worker][Creating and running a worker]]
  - [[#handling-different-event-types][Handling different event types]]
  - [[#graceful-worker-shutdown][Graceful worker shutdown]]
  - [[#monitoring-worker-performance][Monitoring worker performance]]
:END:

** Concepts and purpose

*** Asynchronous event processing

- Event processing :: The worker component provides asynchronous processing of events from the queue:
  - Queue consumption :: Continuously takes events from the event queue
  - Processing isolation :: Separates event processing from HTTP request handling
  - Persistent storage :: Records processed events to a file for durability
  - Independent operation :: Runs as a separate goroutine from the API server
  This asynchronous approach enables better scalability and responsiveness of the API.

*** Worker lifecycle management

- Lifecycle control :: The worker implements a controlled lifecycle with:
  - Initialization :: Sets up dependencies and state at creation time
  - Running :: Processes events in a continuous loop
  - Graceful shutdown :: Ensures proper cleanup when the application terminates
  - Context-based cancellation :: Supports cancellation through context
  This lifecycle management ensures proper resource utilization and cleanup.

*** Event processing reliability

- Processing resilience :: The worker enhances event processing reliability through:
  - Error handling :: Catches and logs processing errors
  - Retry mechanism :: Attempts to reprocess events after failures
  - Metrics tracking :: Records success, failure, and retry counts
  - Backoff strategy :: Waits between retries to prevent resource exhaustion
  This reliability ensures that transient errors don't result in lost events.

*** Observability integration

- Monitoring and tracing :: The worker integrates with observability tools to provide:
  - OpenTelemetry tracing :: Tracks the processing of each event
  - Prometheus metrics :: Collects metrics on processing performance and outcomes
  - Queue wait time tracking :: Measures how long events wait in the queue
  - Processing duration tracking :: Measures how long processing takes
  These observability features aid in monitoring and troubleshooting the system.

** Design and implementation

*** Worker structure

- Worker struct :: Encapsulates the worker's state and dependencies
  - Configuration :: Location for storing processed events
  - Logger :: Structured logger for recording worker events
  - Event queue :: Reference to the event queue for consumption
  - Concurrency controls :: WaitGroup for coordinating shutdown
  - Context management :: Context and CancelFunc for lifecycle control
  #+BEGIN_SRC go
type Worker struct {
	wg         sync.WaitGroup
	Logger     *zerolog.Logger
	EventQueue *data.EventQueue
	Ctx        context.Context
	Cancel     context.CancelFunc
}
  #+END_SRC

*** Worker initialization

- Worker creation :: The `NewWorker` function creates and initializes a worker instance
  - Receives dependencies :: Takes logger, event queue, and parent context
  - Creates derived context :: Sets up a context with cancellation for worker lifecycle
  - Returns initialized worker :: Provides a ready-to-run worker instance
  #+BEGIN_SRC go
func NewWorker(logger *zerolog.Logger, eq *data.EventQueue, ctx context.Context) *Worker {
	ctx, cancel := context.WithCancel(ctx)
	return &Worker{
		Logger:     logger,
		EventQueue: eq,
		Cancel:     cancel,
		Ctx:        ctx,
	}
}
  #+END_SRC

*** Event processing loop

- Run method :: The `Run` method implements the main event processing loop
  - Registration with WaitGroup :: Adds to WaitGroup for shutdown coordination
  - Context monitoring :: Watches for context cancellation to stop processing
  - Event consumption :: Retrieves events from the queue
  - Event processing :: Handles different event types with appropriate processing
  - Error handling :: Catches and handles processing errors with retries
  - Metrics collection :: Records metrics about processing outcomes
  This loop continues until the context is cancelled during shutdown.
  #+BEGIN_SRC go
func (w *Worker) Run(ctx context.Context) {
	runCtx := w.Ctx
	w.wg.Add(1)
	defer w.wg.Done()
	
	for {
		select {
		case nEvent := <-w.EventQueue.Events:
			// Process event with tracing and metrics
			spanCtx, span := otel.Tracer("Worker.Tracer").Start(ctx, "Worker.Span")
			
			// Determine event type for metrics
			var EventType string
			switch nEvent.(type) {
			case *data.EventLog:
				EventType = "log"
			case *data.EventMetric:
				EventType = "metric"
			}
			
			// Measure queue wait time and record metrics
            // [Queue wait time measurement code omitted for brevity]
            
			// Process the event with error handling and retries
			err := processEvent(spanCtx, nEvent)
			if err != nil {
				// Handle error with retry logic
                // [Error handling and retry code omitted for brevity]
			}
			
			// Record metrics and finish span
            // [Metrics recording code omitted for brevity]
			
		case <-runCtx.Done():
			w.Logger.Info().Msg("worker run loop exiting due to context cancellation")
			return
		}
	}
}
  #+END_SRC

*** Event processing implementation

- Process event function :: The `processEvent` function handles individual events
  - Tracing instrumentation :: Creates a span for tracking event processing
  - Event metadata extraction :: Gets metadata from the event
  - Digest calculation :: Computes a hash of the event metadata
  - Processing simulation :: Simulates processing time for demonstration
  - Result persistence :: Writes processing results to a file
  This function implements the core business logic for event processing.
  #+BEGIN_SRC go
func processEvent(ctx context.Context, event data.Event) error {
	ctx, span := otel.Tracer("Worker.ProcessEvent.Tracer").Start(ctx, "Worker.ProcessEvent.Span")
	defer span.End()

	// Extract event metadata
	eMeta := event.GetMetadata()
	
	// Serialize to JSON and calculate hash
	jMeta, err := helpers.MarshalJson(ctx, eMeta)
	if err != nil {
		span.RecordError(err)
		span.SetStatus(codes.Error, "failed to serialize the event metadata to json format")
		return err
	}

	// Calculate hash, length, and get goroutine ID
	hasher := md5.New()
	hasher.Write(jMeta)
	metaHashHex := hex.EncodeToString(hasher.Sum(nil))
	metaLength := len(jMeta)
	metaGoroutineId := helpers.GetGoroutineID(ctx)

	// Simulate processing time
	firstPhaseProcessTime := time.Since(startTime)
	randomTime := 0.05 + rand.Float32()*(0.2-0.05)
	time.Sleep(time.Duration(randomTime))
	metaProcessingTime := randomTime + float32(firstPhaseProcessTime.Seconds())

	// Create processing result
	processResult := struct {
		Event          data.Event
		Md5            string
		Length         int
		GoRoutineID    uint64
		ProcessingTime string
		ProcessedAt    time.Time
	}{
		Event:          event,
		Md5:            metaHashHex,
		Length:         metaLength,
		GoRoutineID:    metaGoroutineId,
		ProcessingTime: fmt.Sprintf("%.4f", metaProcessingTime),
		ProcessedAt:    time.Now(),
	}

	// Write result to file
	// [File writing code omitted for brevity]

	return nil
}
  #+END_SRC

*** Graceful shutdown

- Shutdown method :: The `Shutdown` method implements graceful worker termination
  - Cancellation :: Cancels the worker's context to signal termination
  - Wait channel :: Creates a channel to track WaitGroup completion
  - Timeout handling :: Uses a select to handle completion or timeout
  - Status reporting :: Reports success or failure of shutdown
  This method ensures all in-progress processing completes before shutdown.
  #+BEGIN_SRC go
func (w *Worker) Shutdown(ctx context.Context) error {
	w.Logger.Info().Msg("initiating worker shutdown")

	w.Cancel() // cancel the worker job

	// Create a channel to signal when WaitGroup is done
	done := make(chan struct{})

	go func() {
		w.wg.Wait()
		close(done)
	}()

	select {
	case <-ctx.Done():
		w.Logger.Warn().Msg("worker graceful shutdown timed out")
		return ctx.Err()
	case <-done:
		w.Logger.Info().Msg("worker shutdown completed successfully")
		return nil
	}
}
  #+END_SRC

** Usage examples

*** Creating and running a worker

Example of basic worker initialization and execution:

#+BEGIN_SRC go
// Create dependencies
logger := zerolog.New(os.Stdout).With().Timestamp().Logger()
ctx := context.Background()
eventQueue := models.NewEventQueue()

// Set output file
worker.CmdProcessedEventFile = "/tmp/processed_events.json"

// Create and start worker
eventWorker := worker.NewWorker(&logger, eventQueue, ctx)
go eventWorker.Run(ctx)

// Add events to queue for processing
eventID := uuid.New().String()
logEvent := models.NewEventLog(eventID, "info", "Test event")
eventQueue.PutEvent(ctx, logEvent)

// Let worker process for a while
time.Sleep(time.Second * 3)

// Shutdown the worker
shutdownCtx, cancel := context.WithTimeout(context.Background(), time.Second*5)
defer cancel()
eventWorker.Shutdown(shutdownCtx)
#+END_SRC

*** Handling different event types

Custom event processing based on event type:

#+BEGIN_SRC go
func processCustomEvent(ctx context.Context, event data.Event) error {
    // Type-specific processing
    switch e := event.(type) {
    case *data.EventLog:
        // Process log event
        logger.Info().
            Str("event_id", e.GetEventID()).
            Str("level", e.Level).
            Str("message", e.Message).
            Msg("Processing log event")
        return processLogEvent(ctx, e)
        
    case *data.EventMetric:
        // Process metric event
        logger.Info().
            Str("event_id", e.GetEventID()).
            Float64("value", e.Value).
            Msg("Processing metric event")
        return processMetricEvent(ctx, e)
        
    default:
        return fmt.Errorf("unsupported event type: %T", event)
    }
}
#+END_SRC

*** Graceful worker shutdown

Example of handling multiple workers during shutdown:

#+BEGIN_SRC go
// Create a worker pool
workers := make([]*worker.Worker, 3)
for i := range workers {
    workers[i] = worker.NewWorker(logger, eventQueue, ctx)
    go workers[i].Run(ctx)
}

// Handle termination signal
sigChan := make(chan os.Signal, 1)
signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
<-sigChan

// Shutdown all workers with timeout
shutdownCtx, cancel := context.WithTimeout(context.Background(), time.Second*10)
defer cancel()

for i, w := range workers {
    logger.Info().Int("worker", i).Msg("Shutting down worker")
    if err := w.Shutdown(shutdownCtx); err != nil {
        logger.Error().Err(err).Int("worker", i).Msg("Worker shutdown failed")
    }
}
#+END_SRC

*** Monitoring worker performance

Example of basic worker metrics collection:

#+BEGIN_SRC go
// Create custom metrics for worker monitoring
successCounter := prometheus.NewCounterVec(
    prometheus.CounterOpts{
        Namespace: "worker",
        Name:      "events_processed_success_total",
        Help:      "Total successfully processed events",
    },
    []string{"event_type"},
)

failureCounter := prometheus.NewCounterVec(
    prometheus.CounterOpts{
        Namespace: "worker",
        Name:      "events_processed_failed_total",
        Help:      "Total failed processed events",
    },
    []string{"event_type"},
)

processingDuration := prometheus.NewHistogramVec(
    prometheus.HistogramOpts{
        Namespace: "worker",
        Name:      "processing_duration_seconds",
        Help:      "Event processing duration in seconds",
        Buckets:   prometheus.DefBuckets,
    },
    []string{"event_type"},
)

// Register metrics
prometheus.MustRegister(successCounter, failureCounter, processingDuration)

// Use metrics in custom event processor
func instrumentedProcessEvent(ctx context.Context, event data.Event) error {
    eventType := getEventType(event)
    start := time.Now()
    
    err := processEvent(ctx, event)
    
    // Record metrics
    duration := time.Since(start).Seconds()
    processingDuration.WithLabelValues(eventType).Observe(duration)
    
    if err != nil {
        failureCounter.WithLabelValues(eventType).Inc()
        return err
    }
    
    successCounter.WithLabelValues(eventType).Inc()
    return nil
}
#+END_SRC